{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearModels_LHCb_PID.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yandexdataschool/MLatMISiS2018/blob/master/02_lab/02-LinearModels_LHCb_PID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Z5n_QsxyAmFk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sample management"
      ]
    },
    {
      "metadata": {
        "id": "GZctvep5M3wW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/hse-aml/hadron-collider-machine-learning/releases/download/Week_2/training.csv.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJfgB766M5sN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gunzip training.csv.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qrsvlB7PNAQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9O2zEz9NHnl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('training.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0VkIgvoTNKw1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YTijCF4YCO0K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature description\n",
        "Here, Spd stands for Scintillating Pad Detector, Prs - Preshower, Ecal - electromagnetic calorimeter, Hcal - hadronic calorimeter, Brem denotes traces of the particles that were deflected by detector\n",
        "\n",
        "Features:\n",
        "\n",
        "* ID - id value for tracks (presents only in the test file for the submitting purposes)\n",
        "* Label - string valued observable denoting particle types. Can take values \"Electron\", \"Muon\", \"Kaon\", \"Proton\", \"Pion\" and \"Ghost\". This column is absent in the test file.\n",
        "* FlagSpd - flag (0 or 1), if reconstructed track passes through Spd\n",
        "* FlagPrs - flag (0 or 1), if reconstructed track passes through Prs\n",
        "* FlagBrem - flag (0 or 1), if reconstructed track passes through Brem\n",
        "* FlagEcal - flag (0 or 1), if reconstructed track passes through Ecal\n",
        "* FlagHcal - flag (0 or 1), if reconstructed track passes through Hcal\n",
        "* FlagRICH1 - flag (0 or 1), if reconstructed track passes through the first RICH detector\n",
        "* FlagRICH2 - flag (0 or 1), if reconstructed track passes through the second RICH detector\n",
        "* FlagMuon - flag (0 or 1), if reconstructed track passes through muon stations (Muon)\n",
        "* SpdE - energy deposit associated to the track in the Spd\n",
        "* PrsE - energy deposit associated to the track in the Prs\n",
        "* EcalE - energy deposit associated to the track in the Hcal\n",
        "* HcalE - energy deposit associated to the track in the Hcal\n",
        "* PrsDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Prs\n",
        "* BremDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Brem\n",
        "* TrackP - particle momentum\n",
        "* TrackPt - particle transverse momentum\n",
        "* TrackNDoFSubdetector1 - number of degrees of freedom for track fit using hits in the tracking sub-detector1\n",
        "* TrackQualitySubdetector1 - chi2 quality of the track fit using hits in the tracking sub-detector1\n",
        "* TrackNDoFSubdetector2 - number of degrees of freedom for track fit using hits in the tracking sub-detector2\n",
        "* TrackQualitySubdetector2 - chi2 quality of the track fit using hits in the tracking sub-detector2\n",
        "* TrackNDoF - number of degrees of freedom for track fit using hits in all tracking sub-detectors\n",
        "* TrackQualityPerNDoF - chi2 quality of the track fit per degree of freedom\n",
        "* TrackDistanceToZ - distance between track and z-axis (beam axis)\n",
        "* Calo2dFitQuality - quality of the 2d fit of the clusters in the calorimeter\n",
        "* Calo3dFitQuality - quality of the 3d fit in the calorimeter with assumption that particle was electron\n",
        "* EcalDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Ecal\n",
        "* EcalDLLbeMuon - delta log-likelihood for a particle candidate to be muon using information from Ecal\n",
        "* EcalShowerLongitudinalParameter - longitudinal parameter of Ecal shower\n",
        "* HcalDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Hcal\n",
        "* HcalDLLbeMuon - delta log-likelihood for a particle candidate to be using information from Hcal\n",
        "* RICHpFlagElectron - flag (0 or 1) if momentum is greater than threshold for electrons to produce Cherenkov light\n",
        "* RICHpFlagProton - flag (0 or 1) if momentum is greater than threshold for protons to produce Cherenkov light\n",
        "* RICHpFlagPion - flag (0 or 1) if momentum is greater than threshold for pions to produce Cherenkov light\n",
        "* RICHpFlagKaon - flag (0 or 1) if momentum is greater than threshold for kaons to produce Cherenkov light\n",
        "* RICHpFlagMuon - flag (0 or 1) if momentum is greater than threshold for muons to produce Cherenkov light\n",
        "* RICH_DLLbeBCK - delta log-likelihood for a particle candidate to be background using information from RICH\n",
        "* RICH_DLLbeKaon - delta log-likelihood for a particle candidate to be kaon using information from RICH\n",
        "* RICH_DLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from RICH\n",
        "* RICH_DLLbeMuon - delta log-likelihood for a particle candidate to be muon using information from RICH\n",
        "* RICH_DLLbeProton - delta log-likelihood for a particle candidate to be proton using information from RICH\n",
        "* MuonFlag - muon flag (is this track muon) which is determined from muon stations\n",
        "* MuonLooseFlag muon flag (is this track muon) which is determined from muon stations using looser criteria\n",
        "* MuonLLbeBCK - log-likelihood for a particle candidate to be not muon using information from muon stations\n",
        "* MuonLLbeMuon - log-likelihood for a particle candidate to be muon using information from muon stations\n",
        "* DLLelectron - delta log-likelihood for a particle candidate to be electron using information from all subdetectors\n",
        "* DLLmuon - delta log-likelihood for a particle candidate to be muon using information from all subdetectors\n",
        "* DLLkaon - delta log-likelihood for a particle candidate to be kaon using information from all subdetectors\n",
        "* DLLproton - delta log-likelihood for a particle candidate to be proton using information from all subdetectors\n",
        "* GhostProbability - probability for a particle candidate to be ghost track. This variable is an output of classification model used in the tracking algorithm.\n",
        "\n",
        "Delta log-likelihood in the features descriptions means the difference between log-likelihood for the mass hypothesis that a given track is left by some particle (for example, electron) and log-likelihood for the mass hypothesis that a given track is left by a pion (so, DLLpion = 0 and thus we don't have these columns). This is done since most tracks (~80%) are left by pions and in practice we actually need to discriminate other particles from pions. In other words, the null hypothesis is that particle is a pion.\n"
      ]
    },
    {
      "metadata": {
        "id": "GpKicizuAfIa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# # Feature enigineering\n",
        "Feature selection and preprocessing, model validation"
      ]
    },
    {
      "metadata": {
        "id": "DerPH3IaNSKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FgDawCNFOIhM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's consider PID between two particle types for simplicity:"
      ]
    },
    {
      "metadata": {
        "id": "v3ITGCCvNTR2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = data[(data.Label == 'Kaon') | (data.Label == 'Pion')].copy()\n",
        "\n",
        "features = [col for col in data.columns if col != 'Label']\n",
        "data['Label'] = (data.Label == 'Kaon').astype(float)\n",
        "\n",
        "print(len(data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQOE5qWdN61T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model, metrics, model_selection, preprocessing\n",
        "train, test = model_selection.train_test_split(data, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNoNHvnBhpPo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Selecting the best features is quite an important and non-trivial part of building machine learning models. Scikit-learn has a number of ways to automate this process - to be used with caution - see [this page](https://scikit-learn.org/stable/modules/feature_selection.html) for more details.\n",
        "\n",
        "At this point we are not going to use these tools, but rather do a really simple thing: will score each feature with `roc_auc_score` to find those giving maximum separation between classes."
      ]
    },
    {
      "metadata": {
        "id": "aplWLcUHb8zl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build an array of scores of form [(feature1, score1), (feature2, score2), ...]\n",
        "scores = [(f, metrics.roc_auc_score(data.Label, data[f])) for f in features]\n",
        "\n",
        "# Sort this array by the scores in descending order.\n",
        "# As AUC is symmetric with respect to 0.5, we'll sort\n",
        "# by max(score, 1-score):\n",
        "scores = (sorted(scores, key=lambda x: -max(x[1], 1-x[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_aceKBydcTH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print top 10:\n",
        "print(\"Feature : roc_auc_score \\n\")\n",
        "for f, score in scores[:10]:\n",
        "  print(\"{} : {}\".format(f, score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W26zBh7jT10f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So, just a single `DLLkaon` feature gives us an AUC of 94%!\n",
        "Let's see if we can beat this score."
      ]
    },
    {
      "metadata": {
        "id": "7UQOGSkXTxHp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The simplest thing we can do is to take, say, 10 best features and feed them into a logistic regression model:"
      ]
    },
    {
      "metadata": {
        "id": "HdiSrUi1kTIP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top10_features = list(list(zip(*scores))[0][:10])\n",
        "\n",
        "def get_features(dataset):\n",
        "  return dataset[top10_features]\n",
        "\n",
        "model = linear_model.LogisticRegression()\n",
        "\n",
        "model.fit(get_features(train), train.Label)\n",
        "\n",
        "preds_train = model.predict_proba(get_features(train))[:,1]\n",
        "preds_test  = model.predict_proba(get_features(test ))[:,1]\n",
        "\n",
        "print(metrics.roc_auc_score(train.Label, preds_train))\n",
        "print(metrics.roc_auc_score(test .Label, preds_test ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-8zvlxOmZ1e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hmm, that just decreased the score.\n",
        "\n",
        "Let's look at the range of these features:"
      ]
    },
    {
      "metadata": {
        "id": "2mJIEk8yl5bV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for f in top10_features:\n",
        "  print(\"{:20s} : ({:10.2f}, {:10.2f})\".format(f, data[f].min(), data[f].max()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N8nApG_PnIME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can notice two things:\n",
        "1.   ranges are very different\n",
        "2.   some variables have 'unnatural' minimum of -999\n",
        "\n",
        "Let's discuss problem 1 first. Our model treats its inputs as vectors of $R^M$ space ($M$ is the number of features), and calculates things like dot-product ${\\bf W}\\cdot{\\bf x}$. This assumes that all the components of these vectors are objects of the same nature and have the same units. Obviously this is not the case. We can however emulate this by scaling the components of these vectors to have same variance and mean:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OYeozqZTpHo0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_features(dataset):\n",
        "  return dataset[top10_features]\n",
        "\n",
        "scaler = preprocessing.RobustScaler()\n",
        "scaler.fit(get_features(train))\n",
        "\n",
        "model = linear_model.LogisticRegression()\n",
        "\n",
        "model.fit(scaler.transform(get_features(train)), train.Label)\n",
        "\n",
        "preds_train = model.predict_proba(scaler.transform(get_features(train)))[:,1]\n",
        "preds_test  = model.predict_proba(scaler.transform(get_features(test )))[:,1]\n",
        "\n",
        "print(metrics.roc_auc_score(train.Label, preds_train))\n",
        "print(metrics.roc_auc_score(test .Label, preds_test ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0iasmOhpZ1k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This increased the score slightly.\n",
        "\n",
        "Now, problem 2. Let's have a look at one of these features with -999 minimum:"
      ]
    },
    {
      "metadata": {
        "id": "C_1JdA39pi64",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist(data.RICH_DLLbeKaon, bins=300);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gz44uuA1psx8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note the standalone peak near -1000 (actually, -999). Looks like some discreet value was used to denote the cases when `RICH_DLLbeKaon` could not be calculated.\n",
        "\n",
        "The simplest thing we can do with it is to just replace -999 by the mean of the feature, but since in such a way we'll lose this information, let's encode it into a new feature:"
      ]
    },
    {
      "metadata": {
        "id": "tujvqW4aeFHb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_outlier(column, value=-999):\n",
        "  \"\"\"\n",
        "  This function takes a single pandas column and returns a dataframe\n",
        "  with two columns: same column with all occurrences of `value`\n",
        "  replaced by mean and a binary `column == value` column\n",
        "  \"\"\"\n",
        "  is_out = (column == value)\n",
        "  is_out.name += '_out'\n",
        "  \n",
        "  mean = column[~is_out].mean()\n",
        "  column = column.copy()\n",
        "  column[is_out] = mean\n",
        "  \n",
        "  return pd.concat([column, is_out.astype(float)], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rw8Q7OfBrFsY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "outlier_columns = [f for f in top10_features if (data[f] == -999).sum() > 0]\n",
        "print(outlier_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wNE_pczEr2VW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_features(dataset):\n",
        "  return pd.concat([convert_outlier(dataset[f]) if f in outlier_columns else\n",
        "                    dataset[f] for f in top10_features], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Kls0jW_WQEF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's go to our final training."
      ]
    },
    {
      "metadata": {
        "id": "-SpGlxT1aBrY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.RobustScaler()\n",
        "scaler.fit(get_features(train))\n",
        "\n",
        "model = linear_model.LogisticRegression()\n",
        "\n",
        "model.fit(scaler.transform(get_features(train)), train.Label)\n",
        "\n",
        "preds_train = model.predict_proba(scaler.transform(get_features(train)))[:,1]\n",
        "preds_test  = model.predict_proba(scaler.transform(get_features(test )))[:,1]\n",
        "\n",
        "print(metrics.roc_auc_score(train.Label, preds_train))\n",
        "print(metrics.roc_auc_score(test .Label, preds_test ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTAj5S6gYipa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fpr_, tpr_, _ = metrics.roc_curve(test.Label, preds_test )\n",
        "fpr_dll, tpr_dll, _ = metrics.roc_curve(test.Label, test.DLLkaon)\n",
        "\n",
        "plt.plot(fpr_dll, tpr_dll, label='DLLkaon')\n",
        "plt.plot(fpr_, tpr_, label='Our Model')\n",
        "plt.legend()\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aA3vEIBKsFNF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Huh! We've finally beaten the `DLLkaon` score."
      ]
    },
    {
      "metadata": {
        "id": "kvG8ZSwZV71M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But there is no panacea for feature selection/dimensionality reduction. In many real examples you can just choose appropriate feature selection algorithm from sklearn. However, in certain cases you obliged to make feature engineering to accept the compromise between performance measure and expensiveness."
      ]
    },
    {
      "metadata": {
        "id": "tJFbhMuBOL1I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Resampling methods\n",
        "## k-fold cross validation\n",
        "Now let's use the k-fold cross validation technique to ensure this is indeed the case.\n",
        "\n",
        "k-fold cross-validation randomly divides the data into k blocks of roughly equal size. Each of the blocks is left out in turn and the other k-1 blocks are used to train the model. The held out block is predicted and these predictions are summarized into some type of performance measure (e.g. accuracy, root mean squared error (RMSE), etc.). The k estimates of performance are averaged to get the overall resampled estimate."
      ]
    },
    {
      "metadata": {
        "id": "KbtFyA5fsoEX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "aucs_single = []\n",
        "aucs_model = []\n",
        "\n",
        "for i_train, i_test in kf.split(data):\n",
        "  train = data.iloc[i_train]\n",
        "  test  = data.iloc[i_test ]\n",
        "  \n",
        "  scaler = preprocessing.RobustScaler()\n",
        "  scaler.fit(get_features(train))\n",
        "  \n",
        "  model = linear_model.LogisticRegression()\n",
        "  model.fit(scaler.transform(get_features(train)), train.Label)\n",
        "\n",
        "  preds_test = model.predict_proba(\n",
        "      scaler.transform(get_features(test))\n",
        "  )[:,1]\n",
        "  \n",
        "  aucs_model .append(metrics.roc_auc_score(test.Label, preds_test))\n",
        "  aucs_single.append(metrics.roc_auc_score(test.Label, test.DLLkaon))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZIL89BHsn_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 1.7))\n",
        "plt.scatter(aucs_model , [0] * len(aucs_model ), s=100, alpha=0.5, c='r', label='Our model');\n",
        "plt.scatter(aucs_single, [0] * len(aucs_single), s=100, alpha=0.5, c='b', label='just DLLkaon');\n",
        "plt.yticks([]);\n",
        "plt.ylim(-0.2, 0.4)\n",
        "plt.xlabel(\"AUC\");\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}